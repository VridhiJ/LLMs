{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\" style=\"color:green;font-size: 3em;\">\n",
    "Implementing Fine-tuning Techniques</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Implementing various fine-tuning methods as described in different papers, specifically LoRA and IA3.\n",
    "\n",
    "We will do this in 3 parts:\n",
    "\n",
    "Pt1:\n",
    "\n",
    "In this notebook, we will:\n",
    "\n",
    "- Evaluate the perplexity of a causal language model.\n",
    "- Fine-tune a sequence classification model using different learning rates and analyze its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets hf_xet -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "# importing required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import collections\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from typing import List\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM, T5Tokenizer, T5ForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two main types of models here: causal models and sequence classification models. The primary difference between them lies in their applications and functionality.\n",
    "\n",
    "#### Causal Models\n",
    "\n",
    "Causal models, also known as autoregressive models, generate the next word in a sequence based on the preceding words. They are used for tasks such as text generation, language modeling, machine translation, and speech recognition. These models operate unidirectionally, predicting the next token using only previous tokens.\n",
    "\n",
    "\n",
    "#### Sequence Classification Models\n",
    "\n",
    "Sequence classification models categorize a given input sequence into predefined categories. They are useful for tasks like sentiment analysis, spam detection, topic classification, named entity recognition (NER), and document classification. These models often process the entire input sequence at once, using context from all tokens to make a classification decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will initialize a causal model, specifically OPT-125m. When initializing a model, it is important to also initialize the corresponding tokenizer, as it handles the preprocessing of text data into a format that the model can understand.\n",
    "\n",
    "More about the OPT-125m model and its capabilities [here](https://huggingface.co/facebook/opt-125m).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a197d6c204e48879c4ebbfe06085552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/651 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f614940fbdfe448fa9aec2c2484269c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/251M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c125d3816741838486f6c4225ff985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/251M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1587468ede87475e9ded6bc0625eb98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69de0e9838dd48d78c45ae303a43878a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1e1d7a24524614bc1e25b76f5234b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fac57351c2b41e08724656c5f864eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8a25b0fc08474aae671cd5889e22bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the causal model\n",
    "causal_model_name = \"facebook/opt-125m\"\n",
    "causal_model = AutoModelForCausalLM.from_pretrained(causal_model_name).to(device)\n",
    "\n",
    "# Import the tokenizer\n",
    "causal_tokenizer = AutoTokenizer.from_pretrained(causal_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset for this task is Wikitext, which is a collection of articles from Wikipedia. This dataset is widely used for language modeling and text generation tasks because of its comprehensive and diverse range of topics. To read more about the Wikitext dataset and its features [here](https://huggingface.co/datasets/Salesforce/wikitext)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d940dde6f5374adcb8bef184b6e97769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad72e0b540134343866f32aa72badb8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/733k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525ecb72f5404460989702f0f5d03da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/6.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd2ac3602a3449782fdfac460497323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/657k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6083cbeb90ac4d1a9c47d57f0c48790f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9864293bfcbf42a198a288f02a55b3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0191adf2c4b34753bf68c26a2b6c2586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import wikitext dataset\n",
    "causal_test = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"test\")\n",
    "causal_test_encodings = causal_tokenizer(\"\\n\\n\".join(causal_test[\"text\"]), return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will evaluate our model's effectiveness on the Wikitext dataset, an industry-standard benchmark for language modeling tasks. We will use perplexity to assess how well our model generates text.\n",
    "\n",
    "Perplexity measures how well a language model predicts the next word in a sequence. It is calculated as the exponentiated average negative log-likelihood of a sequence. A lower perplexity score indicates better performance, meaning the model is more accurate and confident in its predictions. Perplexity is a standard metric for comparing models and evaluating their ability to generate natural-sounding text. For more details on perplexity, read [here](https://huggingface.co/docs/transformers/en/perplexity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the method to calculate the perplexity\n",
    "def calc_perplexity(model, encodings, stride):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "  model: our pretrained language model that we are evaluating on\n",
    "  encodings: input encodings containing input_ids and other relevant attributes\n",
    "  stride: the step size for segmenting the input sequence\n",
    "\n",
    "  Returns:\n",
    "  The perplexity of the model on the given dataset.\n",
    "  \"\"\"\n",
    "\n",
    "  # Define max_length and seq_len\n",
    "  max_length = 1024\n",
    "  seq_len = encodings.input_ids.size(1)\n",
    "\n",
    "  nlls = []\n",
    "  prev_end_loc = 0\n",
    "\n",
    "  # Loop through the sequence with the given stride\n",
    "  for begin_loc in tqdm(range(0, seq_len, stride)):\n",
    "      end_loc = min(begin_loc + max_length, seq_len)\n",
    "      trg_len = end_loc - prev_end_loc\n",
    "\n",
    "      # Get the input_ids for the current chunk and move to the correct device\n",
    "      input_ids = encodings.input_ids[:, begin_loc: end_loc].to(model.device)\n",
    "      target_ids = input_ids.clone()\n",
    "\n",
    "      # Mask out non-target positions\n",
    "      target_ids[:, :-trg_len] = -100\n",
    "\n",
    "      # Ensure no gradients are calculated\n",
    "      with torch.no_grad():\n",
    "          # Get the model outputs\n",
    "          outputs = model(input_ids, labels=target_ids)\n",
    "          neg_log_likelihood = outputs.loss\n",
    "\n",
    "      nlls.append(neg_log_likelihood)\n",
    "\n",
    "      prev_end_loc = end_loc\n",
    "      if end_loc == seq_len:\n",
    "          break\n",
    "\n",
    "  # Return the perplexity\n",
    "  return torch.exp(torch.stack(nlls).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 268/1124 [00:47<03:21,  4.24it/s]"
     ]
    }
   ],
   "source": [
    "## Calculate the perplexity of our causal model\n",
    "calc_perplexity(causal_model, causal_test_encodings, 256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
